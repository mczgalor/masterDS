{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemas distribuidos 3: SPARK STREAMING con KAFKA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M.C. Gálvez Ortiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Proceso inicial y setup:\n",
    "\n",
    "1. Se crea el entorno de Anaconda Python para Python v3.5. \n",
    "2. En el entorno, se ejecuta zookeeeper y después Kafka.\n",
    "3. Se crea un directorio `checkpoint`, en este caso dentro del subdirectorio `data` donde también se copia el fichero con los tweets a analizar, **DATASET-Twitter-23-26-Mar-2014-MotoGP-Qatar.csv**.\n",
    "4. Se ejecuta el programa que hace de productor leyendo el fichero de tweets. Se ha usado el 5-kafka_producer.py o el 3-kafka_producer.py proporcionado en los ejemplos de clase.\n",
    "`python 5-kafka_producer.py 0.1 0.3 Quatar_GP_2014 data/DATASET-Twitter-23-26-Mar-2014-MotoGP-Qatar.csv`.\n",
    "5. Se lanza el jupyter-notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importación de dependencias y funciones.\n",
    "from __future__ import print_function\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from operator import add\n",
    "from operator import sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Carga de paquetes externos.\n",
    "import os\n",
    "packages = \"org.apache.spark:spark-streaming-kafka-0-8_2.11:2.2.1\"\n",
    "\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = (\n",
    "    \"--packages {0} pyspark-shell\".format(packages)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Activación del contexto spark.\n",
    "sc = SparkContext(appName=\"PracticaSD3_Quatar_GP_2014\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creación del contexto de Spark Streaming.\n",
    "ssc = StreamingContext(sc, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parseo de datos.\n",
    "import csv\n",
    "\n",
    "def parseOrder(line):\n",
    "    #print(line)\n",
    "    s=next(csv.reader([line]))\n",
    "    \n",
    "       \n",
    "    try:\n",
    "        return [{\"Id\": s[0], \"Parent_sys_id\": s[1], \"Source\": s[2],\n",
    "               \"Mentions\": s[3],\"Target\": s[4], \"Name_source\": s[5],\n",
    "               \"Body\": s[6],\"Pub_date\": s[7],\n",
    "               \"URLs\": s[8],\"Tipe_action\": s[9],\n",
    "              \"Link\": s[10], \"Has_link\": s[11], \"Has_picture\": s[12],\n",
    "              \"Website\": s[13],\n",
    "              \"Country\": s[14],\"Activity\": s[15], \"Followers\": s[16],\n",
    "               \"Following\": s[17],\"Location\": s[18]}]\n",
    "    \n",
    "    \n",
    "    except Exception as err:\n",
    "        print(\"Wrong line format (%s): \" % line)\n",
    "        return []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Envio de datos a kafka con la misma dirección que usa el producer para mandar los datos.\n",
    "\n",
    "kafkaBrokerIPPort = \"127.0.0.1:9092\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kafka: lectura de datos con el mismo topic lanzado en el producer.\n",
    "kafkaParams = {\"metadata.broker.list\": kafkaBrokerIPPort}\n",
    "stream = KafkaUtils.createDirectStream(ssc, [\"Quatar_GP_2014\"], kafkaParams)\n",
    "stream = stream.map(lambda o: str(o[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Calcular el número total de menciones recibidas por cada cuenta de usuario durante el intervalo de 5 segundos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lectura de la lista que va llegando en el streaming. \n",
    "\n",
    "lista = stream.flatMap(parseOrder)\n",
    "\n",
    "#Como dentro del campo \"Menciones\" las diferentes menciones estan separadas por comas,\n",
    "# se hace el mapeo dividiendo el campo, se asigna un valor 1 a cada mención encontrada\n",
    "# creando la tupla clave-valor, y se hace la suma por clave en el \"reduceByKey\".\n",
    "\n",
    "menciones = lista.flatMap(lambda o: (o['Mentions'].split(','))) \\\n",
    "                  .map(lambda u: (u, 1)).reduceByKey(lambda a, b: a+b)\n",
    "     \n",
    "menciones.pprint()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Calcular la frecuencia total acumulada de apariciones de cada hashtag en el campo body, actualizando un ranking con los 5 hashtags con mayor frecuencia de aparición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se define una función suma.\n",
    "def update_func(new_val, last_sum):\n",
    "    return sum(new_val) + (last_sum or 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lectura de la lista que va llegando en el streaming. \n",
    "lista = stream.flatMap(parseOrder)\n",
    "\n",
    "#Igual que en el ejercicio anterior, se mapea el campo \"Body\" donde se separan las componentes\n",
    "# por espacio en blanco y se seleccionan las que empiecen por \"#\" que señalan hastags.\n",
    "\n",
    "cuerpo_hasht = lista.flatMap(lambda o: (o['Body'].split())).filter(lambda x: x.startswith('#'))      \n",
    "\n",
    "#Se mapea asignando un valor 1 a cada hastags y se hace la suma acumulada usando el \n",
    "#\"updateStateByKey\" con la función suma definida antes.\n",
    "\n",
    "hasht_ac=cuerpo_hasht.map(lambda u: (u,1)).updateStateByKey(update_func)\n",
    "\n",
    "#Para sacar el top 5, se ordenan el resultado de la suma acumulada de mayor a menor, \n",
    "#tupla (hashtag,valor suma acumulada), se mapea seleccionando la componente primera de \n",
    "#la tupla, esto es el hastags, se indexa y se filtra solo a los primeros 5 índices.\n",
    "\n",
    "topS5 = hasht_ac.transform(lambda a: a.sortBy(lambda x: x[1], False).map(lambda x: x[0])\\\n",
    "                                     .zipWithIndex().filter(lambda x: x[1] < 5))\n",
    "                                     \n",
    "topS5.pprint()\n",
    "\n",
    "ssc.checkpoint(\"data/checkpoint/\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Calcular en una ventana temporal 20 segundos con offset de 10 segundos la frecuencia de aparición de cada uno de los 3 posibles tipos de tweets (TW-RT-MT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lectura de la lista que va llegando en el streaming. \n",
    "lista = stream.flatMap(parseOrder)\n",
    "\n",
    "#Se mapea la lista en el campo \"Tipe_action\", asignando valor 1 y se hace la suma por clave \n",
    "#y por ventana, donde en el offset del 10 segundos se suman los tweets de cada tipo que van\n",
    "# entrando en la ventana y se restan los que van saliendo.\n",
    "\n",
    "tweetsPerWindow = lista.map(lambda x: (x['Tipe_action'],1)).reduceByKeyAndWindow(add, sub, windowDuration=20,slideDuration=10)\n",
    "\n",
    "tweetsPerWindow.repartition(1).pprint()\n",
    "\n",
    "sc.setCheckpointDir(\"data/checkpoint/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comienzo de spark-streaming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2018-07-15 12:14:55\n",
      "-------------------------------------------\n",
      "('motogp', 66)\n",
      "('andreaiannone29', 4)\n",
      "('laureussport', 8)\n",
      "('marcmarquez93', 47)\n",
      "('lorenzo99', 4)\n",
      "('valeyellow46', 33)\n",
      "('aleixespargaro', 4)\n",
      "('19bautista', 5)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-07-15 12:14:55\n",
      "-------------------------------------------\n",
      "('#motogp', 0)\n",
      "('#qatar', 1)\n",
      "('#lwsa14', 2)\n",
      "('#fb', 3)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-07-15 12:15:00\n",
      "-------------------------------------------\n",
      "('motogp', 26)\n",
      "('marcmarquez93', 26)\n",
      "('valeyellow46', 26)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-07-15 12:15:00\n",
      "-------------------------------------------\n",
      "('#motogp', 0)\n",
      "('#qatar', 1)\n",
      "('#lwsa14', 2)\n",
      "('#fb', 3)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-07-15 12:15:00\n",
      "-------------------------------------------\n",
      "('MT', 92)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-07-15 12:15:05\n",
      "-------------------------------------------\n",
      "('motogp', 19)\n",
      "('26_danipedrosa', 1)\n",
      "('officialhaoyama', 1)\n",
      "('marcmarquez93', 17)\n",
      "('nickyhayden', 1)\n",
      "('valeyellow46', 17)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-07-15 12:15:05\n",
      "-------------------------------------------\n",
      "('#motogp', 0)\n",
      "('#qatar', 1)\n",
      "('#lwsa14', 2)\n",
      "('#fb', 3)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-07-15 12:15:10\n",
      "-------------------------------------------\n",
      "('motogp', 27)\n",
      "('marcmarquez93', 24)\n",
      "('valeyellow46', 24)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-07-15 12:15:10\n",
      "-------------------------------------------\n",
      "('#motogp', 0)\n",
      "('#qatar', 1)\n",
      "('#lwsa14', 2)\n",
      "('#fb', 3)\n",
      "('#gomarc93', 4)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-07-15 12:15:10\n",
      "-------------------------------------------\n",
      "('MT', 138)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-07-15 12:15:15\n",
      "-------------------------------------------\n",
      "('motogp', 27)\n",
      "('andreadovizioso', 14)\n",
      "('yamahamotogp', 1)\n",
      "('marcmarquez93', 12)\n",
      "('valeyellow46', 12)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-07-15 12:15:15\n",
      "-------------------------------------------\n",
      "('#motogp', 0)\n",
      "('#qatar', 1)\n",
      "('#lwsa14', 2)\n",
      "('#fb', 3)\n",
      "('#gomarc93', 4)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-07-15 12:15:20\n",
      "-------------------------------------------\n",
      "('motogp', 23)\n",
      "('andreadovizioso', 1)\n",
      "('26_danipedrosa', 18)\n",
      "('marcmarquez93', 18)\n",
      "('valeyellow46', 18)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-07-15 12:15:20\n",
      "-------------------------------------------\n",
      "('#motogp', 0)\n",
      "('#qatar', 1)\n",
      "(\"#motogp'\", 2)\n",
      "('#lwsa14', 3)\n",
      "('#fb', 4)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-07-15 12:15:20\n",
      "-------------------------------------------\n",
      "('MT', 96)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parada de spark-streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2018-07-15 12:15:25\n",
      "-------------------------------------------\n",
      "('motogp', 21)\n",
      "('26_danipedrosa', 21)\n",
      "('marcmarquez93', 21)\n",
      "('valeyellow46', 21)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-07-15 12:15:25\n",
      "-------------------------------------------\n",
      "('#motogp', 0)\n",
      "('#qatar', 1)\n",
      "(\"#motogp'\", 2)\n",
      "('#lwsa14', 3)\n",
      "('#fb', 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.stop(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
